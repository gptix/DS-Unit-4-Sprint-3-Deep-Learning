{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart.\n",
    "import urllib.request\n",
    "\n",
    "# I saved the file at the URL locally,then cut out the forematter and endmatter.\n",
    "\n",
    "fname = \"./shakespeare/shakespeare_cleaned.txt\"\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "with open(fname) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [x.strip() for x in lines]\n",
    "\n",
    "\n",
    "\n",
    "# I take a subset of lines since the full list is huge\n",
    "len(lines)\n",
    "\n",
    "short = int(len(lines) / 50)\n",
    "\n",
    "few_lines = lines[0:short]\n",
    "\n",
    "len(few_lines)\n",
    "text = \" \".join(few_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} \n",
    "\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  11356\n"
     ]
    }
   ],
   "source": [
    "# Create lists of sequences and next characters\n",
    "\n",
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "# encode each character as an integer\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "# initialize lists to hold data\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "# We stop at the last sequence\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    # append an encoded sequence\n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    # append a next character\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (input matrix) & y (target, which i next char)\n",
    "\n",
    "X = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "# X  is a 3-space with dims of (number of sequences), length of sequence, count of unique chars\n",
    "# y is a 2-space with dimensions of (number of sequences), length of sequence\n",
    "# both are very sparse.\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        X[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11356, 40, 71), (11356, 71))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retype for muscle memory\n",
    "\n",
    "# Instantiate a squential model\n",
    "model = Sequential()\n",
    "# Add one LSTM layer\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "# Add an Output Layer\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11356 samples\n",
      "Epoch 1/5\n",
      "11328/11356 [============================>.] - ETA: 0s - loss: 1.4097\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \" shame, Nor thou with public kindness ho\"\n",
      " shame, Nor thou with public kindness hount ol surwerd sharing. Lrone deterkss with their bre cald it menby serss ofange to bet bugr, The pain me, But berond mime prachict, Oan as the liok) Sin of self wored, Even wren no art  of sull tone, Hine well be of it mabe, A done Asl cerurour on call, my songime. Thou carst the ehious and chirts sill, Thas ce the whery if you remert? I whent fortet my and look loves thos be, or mith ip the wher\n",
      "11356/11356 [==============================] - 70s 6ms/sample - loss: 1.4104\n",
      "Epoch 2/5\n",
      "11328/11356 [============================>.] - ETA: 0s - loss: 1.3856\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"ow, For beauty’s pattern to succeeding m\"\n",
      "ow, For beauty’s pattern to succeeding mart’se, of his for, With I te thie do kint, And ston grome, And then sane suth mire you reme, and tingure theres on dat, I sear comurn, No noth love and is ho an wien.   76  Axfayed on slexsterss meld thou fanolly arwind? when heaot fart my doan a cound, I sell tres in my wlof, Tor stinds therepyrt of thre, Bughth my hos deth doth sparle in see your uelont, And thos thit besmeven: Thou thll peavcu\n",
      "11356/11356 [==============================] - 72s 6ms/sample - loss: 1.3854\n",
      "Epoch 3/5\n",
      "11328/11356 [============================>.] - ETA: 0s - loss: 1.3616\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"ay the treasure of his spring: For such \"\n",
      "ay the treasure of his spring: For such val’s To a times in mate, But dllving.   32  Had I ore yey soll in oun midby? What I (ounmey excain to simwing abpued, not white oun foll partiss, and to sell the wit batange your peses, For hall poow aplivigst ofoudd willl heastes owget Ame, Hiol nows, And canguy, Comend, Euse glos, If my enthare everest wied reasand whengue, Abllsber whith thee nepire gine.   31  8h sefistDit selmirt.   78  Thy \n",
      "11356/11356 [==============================] - 72s 6ms/sample - loss: 1.3608\n",
      "Epoch 4/5\n",
      "11328/11356 [============================>.] - ETA: 0s - loss: 1.3395\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"’s shop is hanging still, That hath his \"\n",
      "’s shop is hanging still, That hath his dith’venond in tose of thy wrend, Bot or cautmure. R that thus thy badt necayed, not asones rught’s sish mepray and surling ner loved, For dharpive his lifts the winth deartres mart, thy wrecace bearse mewred an mppouty dills in, Creite, Herry king showlf verurd conted wert having, Ahe beline, Thachinsen, My lake these his prine.   5h  Havy ngintt make time love head dade the win in sailss thise, \n",
      "11356/11356 [==============================] - 73s 6ms/sample - loss: 1.3398\n",
      "Epoch 5/5\n",
      "11328/11356 [============================>.] - ETA: 0s - loss: 1.3139\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"se her babe from faring ill. Presume not\"\n",
      "se her babe from faring ill. Presume not griced prought? Thy too worts se selm guenove, that silith toullone thin, And the prave ho, jow shald lovs thou doth conters’e dich beass than to mus hide his ort from’s I ome, tor shar bead’s of thy headt, Dew’st ebere then sell wher to jlow, Prime, Or she love as your have ’spenent not in hazed rauty? But kidsth uidst is geld thos wid weld exsace, When I four, Widhth I hesure, Thou crilst be as\n",
      "11356/11356 [==============================] - 74s 6ms/sample - loss: 1.3142\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "history = model.fit(X, y,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shakespeare_chars(how_many):\n",
    "    \"\"\"Adds 'how_many' characters to a random string of 'maxlen'\n",
    "    characters selected from 'text'.  Returns the random string plus\n",
    "    the generated characters.\"\"\"\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated = sentence\n",
    "    \n",
    "    for i in range(how_many):\n",
    "        \n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        sentence = sentence[1:] + next_char\n",
    "        generated += next_char\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In other accents do this praise confound: Afrming dosuld dath thas braving worst will, A dese thought muth swill, in hee you arkever, thy wr'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_chars(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S2-NN-DS10",
   "language": "python",
   "name": "u4-s2-nn-ds10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
